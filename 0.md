# Лабораторная работа №0. Установка локальной языковой модели Qwen

**Цель работы:** установить на рабочую машину локальную языковую модель Qwen и выполнить её запуск в локальном окружении.

## План работы
1. Настройка окружения;
2. Запуск языковой модели;
3. Выполнение заданий и анализ результатов.

---

## 1. Настройка и запуск

На первом этапе было выполнено развертывание окружения и подготовка локального запуска модели. После завершения настройки выполнен переход к веб-интерфейсу для дальнейшей работы.

<img width="735" height="147" alt="image" src="https://github.com/user-attachments/assets/5189d022-62d1-48db-96b2-6f2111f3541d" />

<img width="2551" height="1261" alt="image" src="https://github.com/user-attachments/assets/174ef351-79da-4e79-a4e5-9b0f50ad7e64" />

---

## 2. Выполнение заданий

### Задание 1. Настройка системного промпта
В рамках первого задания был настроен системный промпт модели во вкладке `Character`. Дополнительно был установлен аватар для ассистента. Это позволило закрепить роль и стиль поведения ассистента в диалоге (тон общения и формат ответов определяются заданной инструкцией).

<img width="2556" height="1015" alt="image" src="https://github.com/user-attachments/assets/0a9fe324-8767-4312-8f67-6732498cafe8" />

Далее режим работы был переключён на `Chat`, после чего был выполнен тестовый запуск диалога с ассистентом.

<img width="231" height="812" alt="image" src="https://github.com/user-attachments/assets/cce2d986-bc5f-4535-8851-c1231ddc5030" />

**Вывод:** настройка системного промпта влияет на поведение модели в диалоге, задавая контекст, роль ассистента и предпочтительный стиль ответов.

---

### Задание 2. Замена модели ассистента
Во втором задании была выполнена замена модели во вкладке `Parameters`. В качестве альтернативной модели была выбрана и загружена версия `gemma3-1b-Q8_0.gguf`.

<img width="1280" height="757" alt="image" src="https://github.com/user-attachments/assets/3e78cef6-e5fc-459c-a42d-3786baeaaa76" />

**Наблюдение:** после смены модели изменяются характер ответов и качество генерации (скорость, связность, склонность к краткости/подробности), что связано с архитектурой и размером модели, а также параметрами квантования.

---

### Задание 3. Эксперименты с параметрами генерации
Далее были выполнены эксперименты с параметрами генерации, включая `temperature`, `top_p`, `top_k`, `repetition_penalty`.

В ходе тестирования параметр `temperature` был изменён, в частности:
- значение `0.1` — для более детерминированных и “строгих” ответов;
- значение `2.0` — для более вариативных и креативных ответов.

<img width="1280" height="640" alt="image" src="https://github.com/user-attachments/assets/4ed9d8c6-9cfa-4aca-a4c0-4b77cdfdc67d" />

<img width="1280" height="636" alt="image" src="https://github.com/user-attachments/assets/1b2751bf-2b27-48a4-bfe0-ffff323902ce" />

По результатам экспериментов были сделаны следующие выводы:
- `temperature` регулирует степень случайности генерации: при низких значениях ответы более предсказуемые, при высоких — более креативные, но потенциально менее точные.
- `top_p` и `top_k` ограничивают выбор токенов при генерации и помогают снижать вероятность нерелевантных/случайных продолжений, повышая стабильность текста.
- `repetition_penalty` уменьшает вероятность повторов, улучшая разнообразие формулировок.

<img width="1280" height="638" alt="image" src="https://github.com/user-attachments/assets/9a7855b2-0bbf-41f1-b209-6c903c72171f" />

---

## 3. Перечень выполненных заданий

1. Выполнена настройка системного промпта для модели; описано влияние на поведение ассистента.
2. Выполнена замена модели на альтернативную; описаны наблюдаемые изменения.
3. Проведены эксперименты с параметрами генерации (`temperature`, `top_p`, `top_k`, `repetition_penalty`); выполнен анализ влияния на качество и характер ответов.

---
